{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconocimiento_voz_bueno.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZKlZ7d0Ohdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01c702e-8596-4c76-dc2b-6eb64aa37baf"
      },
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import sys\n",
        "from IPython.display import Audio, Javascript\n",
        "from scipy.io import wavfile\n",
        "from base64 import b64decode\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVZY0LOlPCNH"
      },
      "source": [
        "#@title Js and Python\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=6):\n",
        "  try:\n",
        "    from google.colab import output\n",
        "  except ImportError:\n",
        "    print('No possible to import output from google.colab')\n",
        "    return ''\n",
        "  else:\n",
        "    print('Recording')\n",
        "    display(Javascript(RECORD))\n",
        "    s = output.eval_js('record(%d)' % (sec*1000))\n",
        "    fname = 'recorded_audio.wav'\n",
        "    print('Saving to', fname)\n",
        "    b = b64decode(s.split(',')[1])\n",
        "    with open(fname, 'wb') as f:\n",
        "      f.write(b)\n",
        "    return fname\n",
        "#@title Select how to input your audio  { run: \"auto\" }\n",
        "INPUT_SOURCE = 'RECORD' #@param [\"https://storage.googleapis.com/download.tensorflow.org/data/c-scale-metronome.wav\", \"RECORD\", \"UPLOAD\", \"./drive/My Drive/YOUR_MUSIC_FILE.wav\"] {allow-input: true}\n",
        "\n",
        "print('You selected', INPUT_SOURCE)\n",
        "\n",
        "if INPUT_SOURCE == 'RECORD':\n",
        "  uploaded_file_name = record(6)\n",
        "elif INPUT_SOURCE == 'UPLOAD':\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    print(\"ImportError: files from google.colab seems to not be available\")\n",
        "  else:\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "      print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(uploaded[fn])))\n",
        "    uploaded_file_name = next(iter(uploaded))\n",
        "    print('Uploaded file: ' + uploaded_file_name)\n",
        "elif INPUT_SOURCE.startswith('./drive/'):\n",
        "  try:\n",
        "    from google.colab import drive\n",
        "  except ImportError:\n",
        "    print(\"ImportError: files from google.colab seems to not be available\")\n",
        "  else:\n",
        "    drive.mount('/content/drive')\n",
        "    # don't forget to change the name of the file you\n",
        "    # will you here!\n",
        "    gdrive_audio_file = 'YOUR_MUSIC_FILE.wav'\n",
        "    uploaded_file_name = INPUT_SOURCE\n",
        "elif INPUT_SOURCE.startswith('http'):\n",
        "  !wget --no-check-certificate 'https://storage.googleapis.com/download.tensorflow.org/data/c-scale-metronome.wav' -O c-scale.wav\n",
        "  uploaded_file_name = 'c-scale.wav'\n",
        "else:\n",
        "  print('Unrecognized input format!')\n",
        "  print('Please select \"RECORD\", \"UPLOAD\", or specify a file hosted on Google Drive or a file from the web to download file to download')\n",
        "\n",
        "# Function that converts the user-created audio to the format that the model \n",
        "# expects: bitrate 16kHz and only one channel (mono).\n",
        "\n",
        "EXPECTED_SAMPLE_RATE = 16000\n",
        "\n",
        "def convert_audio_for_model(user_file, output_file='converted_audio_file.wav'):\n",
        "  audio = AudioSegment.from_file(user_file)\n",
        "  audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)\n",
        "  audio.export(output_file, format=\"wav\")\n",
        "  return output_file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Converting to the expected format for the model\n",
        "# in all the input 4 input method before, the uploaded file name is at\n",
        "# the variable uploaded_file_name\n",
        "converted_audio_file = convert_audio_for_model(uploaded_file_name)\n",
        "\n",
        "\n",
        "# Loading audio samples from the wav file:\n",
        "sample_rate, audio_samples = wavfile.read(converted_audio_file, 'rb')\n",
        "\n",
        "# Show some basic information about the audio.\n",
        "duration = len(audio_samples)/sample_rate\n",
        "print(f'Sample rate: {sample_rate} Hz')\n",
        "print(f'Total duration: {duration:.2f}s')\n",
        "print(f'Size of the input: {len(audio_samples)}')\n",
        "\n",
        "# Let's listen to the wav file.\n",
        "import speech_recognition as sr\n",
        "r = sr.Recognizer()\n",
        "archivo = sr.AudioFile('converted_audio_file.wav')\n",
        "with archivo as source:\n",
        "  audio = r.record(source)\n",
        "L = r.recognize_google(audio,language ='es-MX')\n",
        "L\n",
        "def open_web(url):\n",
        "  display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
        "\n",
        "from IPython.display import Javascript\n",
        "test = L.split()\n",
        "print(test)\n",
        "print(type(test))\n",
        "palabras = ['carita','mora','youtube','carita de mora','carita mora','carita mora en youtube']\n",
        "if any(palabra in test for palabra in palabras):\n",
        "  open_web('https://www.youtube.com/watch?v=8pLgJz8deXM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlfLJXVKRxZd"
      },
      "source": [
        "Audio(audio_samples, rate=sample_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}